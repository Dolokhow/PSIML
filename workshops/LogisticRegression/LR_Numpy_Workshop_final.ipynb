{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop PSIML 2018\n",
    "## Numpy workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define array\n",
    "a = np.array([1,2,3])\n",
    "\n",
    "# Some basic properties\n",
    "print(\"Array a: \", a)\n",
    "print(\"\\nShape of array a: \", a.shape)\n",
    "print(\"\\nData type of array a: \", a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define matrix\n",
    "b = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Some basic properties\n",
    "print(\"Matrix b: \\n\", b)\n",
    "print(\"\\nShape of matrix b: \", b.shape)\n",
    "print(\"\\nData type of matrix b: \", b.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multidim arrays - tensor\n",
    "c = np.array([[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]])\n",
    "\n",
    "# Some basic properties\n",
    "print(\"Tensor c: \\n\", c)\n",
    "print(\"\\nShape of tensor c: \", c.shape)\n",
    "print(\"\\nData type of tensor c: \", c.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All zeros\n",
    "print(\"All zeros: \\n\", np.zeros((2,2)))\n",
    "\n",
    "# All ones\n",
    "print(\"\\nAll ones: \\n\", np.ones((2,2)))\n",
    "\n",
    "# All same value\n",
    "print(\"\\nAll same value: \\n\", np.full((2,2), 2))\n",
    "\n",
    "# All random\n",
    "# Setting a random seed is important for reproducibility of the code.\n",
    "# It is good practice to use it in ML before moving to actual training as it makes debuging a lot easier.\n",
    "np.random.seed(5)\n",
    "print(\"\\nAll random: \\n\", np.random.random((2,2)))\n",
    "\n",
    "# Identity matrix\n",
    "print(\"\\nIdentity matrix: \\n\", np.eye(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array indexing\n",
    "\n",
    "Indexing goes from 0 for the first element. It is possible to use negative indexes (for example -1 for last element of array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Array a: \", a)\n",
    "print(\"First element of a: \", a[0])\n",
    "print(\"Last element of a: \", a[2])\n",
    "print(\"Last element of a: \", a[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing in matrix and tensor is the same and we can index any column, row etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tensor c: \\n\", c)\n",
    "print(\"\\nValue of c[0]: \\n\", c[0])\n",
    "print(\"\\nValue of c[-2]: \\n\", c[-2])\n",
    "print(\"\\nValue of c[0][1]: \", c[0][1])\n",
    "print(\"Value of c[0][0][0]: \", c[0][0][0])\n",
    "print(\"Value of c[0, 0, 0]: \", c[0, 0, 0])\n",
    "print(\"\\nValue of c[0, :, 0:2]: \\n\", c[0, :, 0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2], [3, 4]], dtype=np.float64)\n",
    "y = np.array([[5, 6], [7, 8]], dtype=np.float64)\n",
    "\n",
    "print(\"Matrix x: \\n\", x)\n",
    "print(\"\\nMatrix y: \\n\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Addition:\\n\", x + y)\n",
    "print(\"Substruction:\\n\", y - x)\n",
    "print(\"Elementwise multiplication:\\n\", x * y)\n",
    "print(\"Multiplication:\\n\", np.matmul(x, y))\n",
    "print(\"Divion:\\n\", x / y)\n",
    "print(\"Square root:\\n\", np.sqrt(x))\n",
    "print(\"Exp:\\n\", np.exp(x))\n",
    "print(\"Dot product:\\n\", np.dot(x[1], y[0]))\n",
    "print(\"Transpose:\\n\", x.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "Broadcasting is one of the most important numpy option. The term broadcasting describes how numpy treats arrays with different shapes during arithmetic operations. Subject to certain constraints, the smaller array is “broadcast” across the larger array so that they have compatible shapes. Broadcasting provides a means of vectorizing array operations so that looping occurs in C instead of Python. It does this without making needless copies of data and usually leads to efficient algorithm implementations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1.0, 2.0, 3.0])\n",
    "b = np.array([2.0, 2.0, 2.0])\n",
    "print(\"a * b, a as vector, b as vector:\", a * b)\n",
    "\n",
    "b = np.array([2])\n",
    "print(\"a * b, a as vector, b as scalar:\", a * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3], [4,5,6]])\n",
    "b = np.array([2,4,6])\n",
    "\n",
    "print(\"a + b, a as matrix, b as vector:\\n\", a + b)\n",
    "print(\"a * b, a as matrix, b as vector:\\n\", a * b)\n",
    "print(\"Dot product of a and b:\\n\", np.dot(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important ML functions:\n",
    "### Sigmoid function:\n",
    "\n",
    "\\begin{equation*}\n",
    "S(x) = \\frac{1}{1 + e^{-x}}\n",
    "\\end{equation*}\n",
    "\n",
    "You can find more at *https://en.wikipedia.org/wiki/Sigmoid_function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # [TODO] Implement sigmoid computation\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sigmoid of \\\"0\\\":\", sigmoid(0))\n",
    "print(\"Expected value: 0.5\")\n",
    "testArray = np.array([1,5])\n",
    "print(\"Sigmoid of [1,5]:\", sigmoid(testArray))\n",
    "print(\"Expected value: [0.73105858 0.99330715]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "x = np.arange(-10., 10., 0.2)\n",
    "y = sigmoid(x)\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLu function:\n",
    "\n",
    "\\begin{equation*}\n",
    "f(x)  = \\begin{cases}\n",
    "    x & \\mbox{if } x > 0 \\\\\n",
    "    0 & \\mbox{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "You can find more at *https://en.wikipedia.org/wiki/Rectifier_(neural_networks)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    # [TODO] Implement ReLu funcion\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Relu of \\\"-5\\\":\", relu(-5))\n",
    "print(\"Expected value: 0\")\n",
    "\n",
    "print(\"Relu of \\\"5\\\":\", relu(5))\n",
    "print(\"Expected value: 5\")\n",
    "\n",
    "testArray = np.array([3,0,-1,2,5,-2])\n",
    "print(\"Relu of [3,0,-1,2,5,-2]:\", relu(testArray))\n",
    "print(\"Expected value: [3 0 0 2 5 0]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting ReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-10., 10., 0.2)\n",
    "rel = relu(x)\n",
    "plt.plot(x,rel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(y=i\\mid \\mathbf{x}) = \\frac{e^{\\mathbf{x}_i}}{\\sum_{k=1}^K e^{\\mathbf{x}_k}}\n",
    "\\end{equation*}\n",
    "\n",
    "You can find more at *https://en.wikipedia.org/wiki/Softmax_function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    # [TODO] Implement softmax function\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testArray = np.array([-1,0.1899,0.4449,0.98990])\n",
    "print(\"Softmax of [-1,0.1899,0.4449,0.98990]: \", softmax(testArray))\n",
    "print(\"Expected value: [0.06311943 0.20745794 0.26771651 0.46170613]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem and data taken from *https://www.kaggle.com/c/titanic*\n",
    "\n",
    "## Goal \n",
    "\n",
    "Based on the provided information about person predict if person survived Titanic crash or not.\n",
    "\n",
    "## Feature explanation\n",
    "\n",
    "| Variable | Definition | Key |\n",
    "| ------------- | ------------- | ------------- |\n",
    "| survival | Survival | 0 = No, 1 = Yes |\n",
    "| pclass | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "| sex | Sex | |\n",
    "| Age | Age in years | |\n",
    "| sibsp | # of siblings / spouses aboard the Titanic | |\n",
    "| parch | # of parents / children aboard the Titanic | |\n",
    "| ticket | Ticket number | |\n",
    "| fare | Passenger fare | |\n",
    "| cabin | Cabin number | |\n",
    "| embarked | Port of Embarkation | C = Cherbourg, Q = Queenstown, S = Southampton |\n",
    "\n",
    "### Variable Notes\n",
    "\n",
    "**pclass**: A proxy for socio-economic status (SES)  \n",
    "1st = Upper  \n",
    "2nd = Middle  \n",
    "3rd = Lower  \n",
    "\n",
    "\n",
    "**age**: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5  \n",
    "\n",
    "**sibsp**: The dataset defines family relations in this way...  \n",
    "Sibling = brother, sister, stepbrother, stepsister  \n",
    "Spouse = husband, wife (mistresses and fiancés were ignored)  \n",
    "\n",
    "**parch**: The dataset defines family relations in this way...  \n",
    "Parent = mother, father  \n",
    "Child = daughter, son, stepdaughter, stepson  \n",
    "\n",
    "Some children travelled only with a nanny, therefore parch=0 for them.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "dataPath = r'Data\\train.csv'\n",
    "\n",
    "def readCSVasNumpy(dataPath):\n",
    "    with open(dataPath,'r') as dest_f:\n",
    "        data_iter = csv.reader(dest_f, delimiter = ',', quotechar = '\"')\n",
    "        data = [data for data in data_iter]\n",
    "    data_array = np.asarray(data, dtype = None)\n",
    "    return data_array\n",
    "\n",
    "data = readCSVasNumpy(dataPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset - Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (data[1:,1]).astype(int)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_fields = [2, 4, 5, 6, 7, 9]\n",
    "features = data[1:, important_fields]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[:,1] = (features[:,1]==\"male\").astype(float)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ageFeatures = features[:,2]\n",
    "age_is_present_mask = np.where(ageFeatures != \"\")\n",
    "averageAge = np.mean(ageFeatures[age_is_present_mask].astype(float))\n",
    "\n",
    "features[np.where(ageFeatures == \"\"),2] = str(averageAge)\n",
    "\n",
    "features = features.astype(float)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIndexes = np.sort(np.random.choice(features.shape[0], int(features.shape[0]*0.7), replace=False))\n",
    "\n",
    "train_features = features[trainIndexes]\n",
    "test_features = np.delete(features, trainIndexes, axis=0)\n",
    "\n",
    "train_labels = labels[trainIndexes]\n",
    "test_labels = np.delete(labels, trainIndexes, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxFeatures = np.max(train_features, axis=0)\n",
    "minFeatures = np.min(train_features, axis=0)\n",
    "\n",
    "train_features = (train_features - minFeatures) / (maxFeatures - minFeatures)\n",
    "test_features = (test_features - minFeatures) / (maxFeatures - minFeatures)\n",
    "\n",
    "train_features = np.append(np.ones((train_features.shape[0], 1)), train_features, axis=1)\n",
    "test_features = np.append(np.ones((test_features.shape[0], 1)), test_features, axis=1)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### Hypothesis:\n",
    "\n",
    "\\begin{equation*}\n",
    "h(x) = \\frac {1}{1+e^{-\\sum_{i=0}^K{w_i x_i}}}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRmodel:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.w = weights\n",
    "        self.b = bias\n",
    "        \n",
    "    def __init__(self, feature_space_size):\n",
    "        self.w = np.ones(feature_space_size-1)\n",
    "        self.b = np.ones(1)\n",
    "            \n",
    "    def evaluate(self, features):   \n",
    "        return sigmoid(np.dot(features[:,1:], self.w) + self.b)\n",
    "    \n",
    "    def getModelParams(self):\n",
    "        return np.append(self.b, self.w)\n",
    "    \n",
    "    def setModelParams(self, params):\n",
    "        self.b = params[0]\n",
    "        self.w = params[1:]\n",
    "\n",
    "\n",
    "model = LRmodel(train_features.shape[1])\n",
    "\n",
    "print(\"Model weights: \", model.w)\n",
    "print(\"Expected values: [1. 1. 1. 1. 1. 1.]\")\n",
    "\n",
    "print(\"Feature vector shape: \", train_features[:,1:].shape)\n",
    "print(\"Expected values: (623, 6)\")\n",
    "\n",
    "print(\"First 3 model evaluations: \", model.evaluate(train_features)[0:3])\n",
    "print(\"Expected values: [0.96802565 0.84066383 0.96923841]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer\n",
    "\n",
    "### Cost function:\n",
    "\n",
    "\\begin{equation*}\n",
    "J = \\frac {1} {n} \\sum_{i=i}^n{cost(h(X_i),Y_i)} \n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "J = \\frac {1} {n} \\sum_{i=i}^n{[-ylog(h(x)) - (1-y)log(1 -h(x))]} \n",
    "\\end{equation*}\n",
    "\n",
    "### Gradient descent:\n",
    "\n",
    "\\begin{equation*}\n",
    "w_i = w_i - \\alpha \\sum_{j=1}^n {(h(X^{(j)}) - y^{(j)}) x_i^{(j)}}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def calculateCost(self, features, labels):\n",
    "        # [TODO] Implement cost function based on the formulas above\n",
    "        return 0\n",
    "    \n",
    "    def calculateGradients(self, features, labels):\n",
    "        # [TODO] Implement gradients function based on the formulas above\n",
    "        return 0\n",
    "    \n",
    "    def updateModel(self, gradient, learningRate):\n",
    "        # [TODO] Implement model update based on the gradients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LRmodel(train_features.shape[1])\n",
    "trainer = Trainer(model)\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "print(\"Starting cost training: \", trainer.calculateCost(train_features, train_labels))\n",
    "print(\"Starting cost test: \", trainer.calculateCost(test_features, test_labels))\n",
    "\n",
    "costFunctionValues = []\n",
    "iters = np.arange(1, 2000, 1)\n",
    "\n",
    "for i in iters:\n",
    "    #print(\"Itteration: \", i)\n",
    "    \n",
    "    # [TODO] Implement one itteration of training\n",
    "    \n",
    "    train_cost = trainer.calculateCost(train_features, train_labels)\n",
    "    test_cost = trainer.calculateCost(test_features, test_labels)\n",
    "    \n",
    "    costFunctionValues.append([train_cost, test_cost])\n",
    "    \n",
    "    #print(\"Training cost: \", train_cost)\n",
    "    #print(\"Test cost: \", test_cost)\n",
    "\n",
    "costFunctionValues = np.array(costFunctionValues)\n",
    "print(\"End cost training: \", costFunctionValues[-1][0])\n",
    "print(\"End cost test: \", costFunctionValues[-1][1])\n",
    "\n",
    "plt.figure(1, figsize=(20, 15))\n",
    "plt.subplot(211)\n",
    "plt.plot(iters, costFunctionValues[:,0])\n",
    "plt.subplot(212)\n",
    "plt.plot(iters, costFunctionValues[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def evaluate(self, features):\n",
    "        predictions = self.model.evaluate(features)\n",
    "        return predictions\n",
    "    \n",
    "    def calculateAPR(self, features, labels, threshold):\n",
    "        predictions = self.evaluate(features)\n",
    "        \n",
    "        numExamples = predictions.shape[0]\n",
    "        binaryPredictions = (predictions > threshold).astype(int)\n",
    "        \n",
    "        positivePredictions = np.where(binaryPredictions == 1)\n",
    "        negativePredictions = np.where(binaryPredictions == 0)\n",
    "        \n",
    "        # [TODO] Implement calculation of TP, FP, TN, FN, Precision, Recall and Accuracy\n",
    "        \n",
    "        # TP - Count of examples that were correctlly predicted as positive examples\n",
    "        \n",
    "        # FP - Count of examples that were incorectlly predicted as positive examples\n",
    "        \n",
    "        # TP - Count of examples that were incorectlly predicted as negative examples\n",
    "        \n",
    "        # TP - Count of examples that were correctlly predicted as negative examples\n",
    "               \n",
    "        return Precision, Recall, Accuracy\n",
    "    \n",
    "    def plotAPR(self, resultsTest, resultsTrain, ranges):\n",
    "        plt.figure(1, figsize=(20, 15))\n",
    "        plt.subplot(211)\n",
    "        plt.plot(ranges, np.matrix(resultsTrain)[:,0], ranges, np.matrix(resultsTrain)[:,1], ranges, np.matrix(resultsTrain)[:,2])\n",
    "        plt.subplot(212)\n",
    "        plt.plot(ranges, np.matrix(resultsTest)[:,0], ranges, np.matrix(resultsTest)[:,1], ranges, np.matrix(resultsTest)[:,2])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(model)\n",
    "t = np.arange(0., 1., 0.001)\n",
    "resultsTest = []\n",
    "resultsTrain = []\n",
    "for i in t:\n",
    "    resultsTest.append(evaluator.calculateAPR(test_features, test_labels, i))\n",
    "    resultsTrain.append(evaluator.calculateAPR(train_features, train_labels, i))\n",
    "\n",
    "evaluator.plotAPR(resultsTest, resultsTrain, t)\n",
    "\n",
    "print(\"Model w: \", model.w, \"\\nModel b: \", model.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "### Regularization cost: \n",
    "\\begin{equation*}\n",
    "J = \\frac {1} {n} \\sum_{i=1}^n{cost(h(X_i),Y_i)} + \\frac {μ}{2}\\sum_{i=1}^m{w_i^2}\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "J = \\frac {1} {n} \\sum_{i=1}^n{[-y log(h(x)) - (1-y) log(1 - h(x))]} + \\frac {μ}{2}\\sum_{i=1}^m{w_i^2}\n",
    "\\end{equation*}\n",
    "\n",
    "### Regularization gradient: \n",
    "\n",
    "\\begin{equation*}\n",
    "w_0 = w_0 - \\alpha [\\frac{1}{n} \\sum_{j=1}^n {(h(X^{(j)}) - y^{(j)}) x_i^{(j)}}]\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "w_i = w_i - \\alpha [\\frac{1}{n} \\big\\langle\\sum_{j=1}^n {(h(X^{(j)}) - y^{(j)}) x_i^{(j)}}\\big\\rangle + {μ} w_i]\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerReg:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def calculateCost(self, features, labels, regParameter):\n",
    "        # [TODO] Implement cost function based on the formulas above\n",
    "        return 0\n",
    "\n",
    "    \n",
    "    def calculateGradients(self, features, labels, regParameter):\n",
    "        # [TODO] Implement gradients function based on the formulas above\n",
    "        return 0\n",
    "\n",
    "    \n",
    "    def updateModel(self, gradient, learningRate):\n",
    "        # [TODO] Implement model update based on the gradients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LRmodel(train_features.shape[1])\n",
    "trainer = TrainerReg(model)\n",
    "\n",
    "regularization_param = 0.01\n",
    "learning_rate = 0.1\n",
    "\n",
    "print(\"Starting cost training: \", trainer.calculateCost(train_features, train_labels, regularization_param))\n",
    "print(\"Starting cost test: \", trainer.calculateCost(test_features, test_labels, regularization_param))\n",
    "\n",
    "costFunctionValues = []\n",
    "iters = np.arange(1, 2000, 1)\n",
    "\n",
    "for i in iters:\n",
    "    #print(\"Itteration: \", i)\n",
    "    \n",
    "    # [TODO] Implement one itteration of training\n",
    "    \n",
    "    train_cost = trainer.calculateCost(train_features, train_labels,regularization_param)\n",
    "    test_cost = trainer.calculateCost(test_features, test_labels,regularization_param)\n",
    "    \n",
    "    costFunctionValues.append([train_cost, test_cost])\n",
    "    \n",
    "    #print(\"Training cost: \", train_cost)\n",
    "    #print(\"Test cost: \", test_cost)\n",
    "\n",
    "costFunctionValues = np.array(costFunctionValues)\n",
    "print(\"End cost training: \", costFunctionValues[-1][0])\n",
    "print(\"End cost test: \", costFunctionValues[-1][1])\n",
    "\n",
    "plt.figure(1, figsize=(20, 15))\n",
    "plt.subplot(211)\n",
    "plt.plot(iters, costFunctionValues[:,0])\n",
    "plt.subplot(212)\n",
    "plt.plot(iters, costFunctionValues[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(model)\n",
    "t = np.arange(0., 1., 0.001)\n",
    "resultsTest = []\n",
    "resultsTrain = []\n",
    "for i in t:\n",
    "    resultsTest.append(evaluator.calculateAPR(test_features, test_labels, i))\n",
    "    resultsTrain.append(evaluator.calculateAPR(train_features, train_labels, i))\n",
    "\n",
    "evaluator.plotAPR(resultsTest, resultsTrain, t)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "print(\"Model w: \", model.w, \"\\nModel b: \", model.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
