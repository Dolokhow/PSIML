{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define array\n",
    "a = np.array([1,2,3])\n",
    "\n",
    "# Some basic properties\n",
    "print(\"Array a: \", a)\n",
    "print(\"\\nShape of array a: \", a.shape)\n",
    "print(\"\\nData type of array a: \", a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define matrix\n",
    "b = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Some basic properties\n",
    "print(\"Matrix b: \\n\", b)\n",
    "print(\"\\nShape of matrix b: \", b.shape)\n",
    "print(\"\\nData type of matrix b: \", b.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Multidim arrays - tensor\n",
    "c = np.array([[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]])\n",
    "\n",
    "# Some basic properties\n",
    "print(\"Tensor c: \\n\", c)\n",
    "print(\"\\nShape of tensor c: \", c.shape)\n",
    "print(\"\\nData type of tensor c: \", c.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All zeros\n",
    "print(\"All zeros: \\n\", np.zeros((2,2)))\n",
    "\n",
    "# All ones\n",
    "print(\"\\nAll ones: \\n\", np.ones((2,2)))\n",
    "\n",
    "# All same value\n",
    "print(\"\\nAll same value: \\n\", np.full((2,2), 2))\n",
    "\n",
    "# All random\n",
    "# Setting a random seed is important for reproducibility of the code.\n",
    "# It is good practice to use it in ML before moving to actual training as it makes debuging a lot easier.\n",
    "np.random.seed(5)\n",
    "print(\"\\nAll random: \\n\", np.random.random((2,2)))\n",
    "\n",
    "# Identity matrix\n",
    "print(\"\\nIdentity matrix: \\n\", np.eye(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array indexing\n",
    "\n",
    "Indexing starts from 0. It is possible to use negative indexes (for example -1 for last element of array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Array a: \", a)\n",
    "print(\"First element of a: \", a[0])\n",
    "print(\"Last element of a: \", a[2])\n",
    "print(\"Last element of a: \", a[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing in matrix and tensor is the same and we can index any column, row etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Tensor c: \\n\", c)\n",
    "print(\"\\nValue of c[0]: \\n\", c[0])\n",
    "print(\"\\nValue of c[-2]: \\n\", c[-2])\n",
    "print(\"\\nValue of c[0][1]: \", c[0][1])\n",
    "print(\"Value of c[0][0][0]: \", c[0][0][0])\n",
    "print(\"Value of c[0, 0, 0]: \", c[0, 0, 0])\n",
    "print(\"\\nValue of c[0, :, 0:2]: \\n\", c[0, :, 0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array([[1, 2], [3, 4]], dtype=np.float64)\n",
    "y = np.array([[5, 6], [7, 8]], dtype=np.float64)\n",
    "\n",
    "print(\"Matrix x: \\n\", x)\n",
    "print(\"\\nMatrix y: \\n\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Addition:\\n\", x + y)\n",
    "print(\"Substruction:\\n\", y - x)\n",
    "print(\"Elementwise multiplication:\\n\", x * y)\n",
    "print(\"Multiplication:\\n\", np.matmul(x, y))\n",
    "print(\"Divison:\\n\", x / y)\n",
    "print(\"Square root:\\n\", np.sqrt(x))\n",
    "print(\"Exp:\\n\", np.exp(x))\n",
    "print(\"Dot product:\\n\", np.dot(x[1], y[0]))\n",
    "print(\"Transpose:\\n\", x.T)\n",
    "print(\"Inverse:\\n\", np.linalg.inv(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "Broadcasting is one of the most important numpy features. The term broadcasting describes how numpy treats arrays with different shapes during arithmetic operations. Subject to certain constraints, the smaller array is \"broadcast\" across the larger array so that they have compatible shapes. Broadcasting provides a means of vectorizing array operations so that looping occurs in C instead of Python. It does this without making needless copies of data and usually leads to efficient algorithm implementations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([1.0, 2.0, 3.0])\n",
    "b = np.array([2.0, 2.0, 2.0])\n",
    "print(\"a * b, a as vector, b as vector:\", a * b)\n",
    "\n",
    "b = np.array([2])\n",
    "print(\"a * b, a as vector, b as scalar:\", a * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3], [4,5,6]])\n",
    "b = np.array([2,4,6])\n",
    "\n",
    "print(\"a + b, a as matrix, b as vector:\\n\", a + b)\n",
    "print(\"a * b, a as matrix, b as vector:\\n\", a * b)\n",
    "print(\"Dot product of a and b:\\n\", np.dot(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important ML functions:\n",
    "### Sigmoid function:\n",
    "\n",
    "\\begin{equation*}\n",
    "S(x) = \\frac{1}{1 + e^{-x}}\n",
    "\\end{equation*}\n",
    "\n",
    "You can find more at *https://en.wikipedia.org/wiki/Sigmoid_function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # [TODO] Implement sigmoid function\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Sigmoid of \\\"0\\\":\", sigmoid(0))\n",
    "print(\"Expected value: 0.5\")\n",
    "testArray = np.array([1,5])\n",
    "print(\"Sigmoid of [1,5]:\", sigmoid(testArray))\n",
    "print(\"Expected value: [0.73105858 0.99330715]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.arange(-10., 10., 0.2)\n",
    "y = sigmoid(x)\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal equations\n",
    "\n",
    "Standard variant\n",
    "\\begin{equation}\n",
    "w = (X^TX)^{-1}X^Ty\n",
    "\\end{equation}\n",
    "\n",
    "Regularized variant\n",
    "\\begin{equation}\n",
    "w = (X^TX+\\lambda I)^{-1}X^Ty\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fixing random seed\n",
    "np.random.seed(5)\n",
    "\n",
    "# Generating synthetic data from exponential function with some noise\n",
    "sampleSize = 20\n",
    "x = sorted(np.random.uniform(0, 4, sampleSize))\n",
    "y = np.exp(x) + np.random.normal(0, 0.01, sampleSize)\n",
    "plt.plot(x, y, 'bo')\n",
    "plt.show()\n",
    "\n",
    "# Save the original vector x because we will be transforming our features\n",
    "xo = x;\n",
    "\n",
    "# Adding column of ones for implicit treatment of bias term\n",
    "x = np.concatenate((np.ones((sampleSize,1)), np.reshape(xo, (sampleSize, 1))), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [TODO] Estimate w via normal equations\n",
    "\n",
    "\n",
    "# [TODO] Compute regression values z using w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot predictions against x (using original x)\n",
    "plt.plot(xo, y, 'bo');\n",
    "plt.plot(xo, z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generating powers of x up to some degree\n",
    "degree = 12\n",
    "for i in range(1, degree):\n",
    "    t = np.reshape(x[:, -1] * xo, (sampleSize, 1))\n",
    "    x = np.concatenate((x, t), 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Play with regularization parameter to tune ridge regression \n",
    "# Start from 10^-6 and increase exponentially\n",
    "lmbd = 0\n",
    "\n",
    "# [TODO] Estimate w using regularized normal equations\n",
    "\n",
    "\n",
    "# [TODO] Compute regression values z using w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot predictions against x\n",
    "plt.plot(xo, y, 'bo');\n",
    "plt.plot(xo, z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "Problem and data taken from *https://www.kaggle.com/c/titanic*\n",
    "\n",
    "### Goal \n",
    "\n",
    "Based on the provided information about person predict if person survived Titanic crash or not.\n",
    "\n",
    "### Feature explanation\n",
    "\n",
    "| Variable | Definition | Key |\n",
    "| ------------- | ------------- | ------------- |\n",
    "| survival | Survival | 0 = No, 1 = Yes |\n",
    "| pclass | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "| sex | Sex | |\n",
    "| Age | Age in years | |\n",
    "| sibsp | # of siblings / spouses aboard the Titanic | |\n",
    "| parch | # of parents / children aboard the Titanic | |\n",
    "| ticket | Ticket number | |\n",
    "| fare | Passenger fare | |\n",
    "| cabin | Cabin number | |\n",
    "| embarked | Port of Embarkation | C = Cherbourg, Q = Queenstown, S = Southampton |\n",
    "\n",
    "### Variable Notes\n",
    "\n",
    "**pclass**: A proxy for socio-economic status (SES)  \n",
    "1st = Upper  \n",
    "2nd = Middle  \n",
    "3rd = Lower  \n",
    "\n",
    "\n",
    "**age**: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5  \n",
    "\n",
    "**sibsp**: The dataset defines family relations in this way...  \n",
    "Sibling = brother, sister, stepbrother, stepsister  \n",
    "Spouse = husband, wife (mistresses and fiancés were ignored)  \n",
    "\n",
    "**parch**: The dataset defines family relations in this way...  \n",
    "Parent = mother, father  \n",
    "Child = daughter, son, stepdaughter, stepson  \n",
    "\n",
    "Some children travelled only with a nanny, therefore parch=0 for them.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "dataPath = r'Data\\train.csv'\n",
    "\n",
    "def readCSVasNumpy(dataPath):\n",
    "    with open(dataPath,'r') as dest_f:\n",
    "        data_iter = csv.reader(dest_f, delimiter = ',', quotechar = '\"')\n",
    "        data = [data for data in data_iter]\n",
    "    data_array = np.asarray(data, dtype = None)\n",
    "    return data_array\n",
    "\n",
    "data = readCSVasNumpy(dataPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = (data[1:,1]).astype(int)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data[0:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select some features\n",
    "important_fields = [2, 4, 5, 6, 7, 9]\n",
    "features = data[1:, important_fields]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trivial dummy coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features[:,1] = (features[:,1]==\"male\").astype(float)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainIndexes = np.sort(np.random.choice(features.shape[0], int(features.shape[0]*0.7), replace=False))\n",
    "\n",
    "trainFeatures = features[trainIndexes]\n",
    "testFeatures = np.delete(features, trainIndexes, axis=0)\n",
    "\n",
    "trainLabels = labels[trainIndexes]\n",
    "testLabels = np.delete(labels, trainIndexes, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Identify columns with missing data\n",
    "\n",
    "print(np.sum(trainFeatures == \"\", 0))\n",
    "print(np.sum(testFeatures == \"\", 0))\n",
    "print(trainFeatures.shape)\n",
    "print(testFeatures.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute average of existing values on the TRAINING SET and \n",
    "# use it to substitute missing values in both sets\n",
    "\n",
    "# Column with missing values\n",
    "col = 2\n",
    "\n",
    "agePresentMask = np.where(trainFeatures[:,col] != \"\")\n",
    "averageAge = np.mean(trainFeatures[agePresentMask,col].astype(float))\n",
    "trainFeatures[np.where(trainFeatures[:,col] == \"\"),col] = str(averageAge)\n",
    "\n",
    "testFeatures[np.where(testFeatures[:,col] == \"\"),col] = str(averageAge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert everything to floats so we can transform features\n",
    "\n",
    "trainFeatures = trainFeatures.astype(float)\n",
    "testFeatures = testFeatures.astype(float)\n",
    "print(trainFeatures)\n",
    "print(testFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scale features to interval [0,1]\n",
    "\n",
    "maxFeatures = np.max(trainFeatures, axis=0)\n",
    "minFeatures = np.min(trainFeatures, axis=0)\n",
    "\n",
    "trainFeatures = (trainFeatures - minFeatures) / (maxFeatures - minFeatures)\n",
    "testFeatures = (testFeatures - minFeatures) / (maxFeatures - minFeatures)\n",
    "\n",
    "print(trainFeatures)\n",
    "print(testFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding column of ones for implicit treatment of bias term\n",
    "\n",
    "trainFeatures = np.concatenate((np.ones((trainFeatures.shape[0],1)), trainFeatures), 1)\n",
    "testFeatures = np.concatenate((np.ones((testFeatures.shape[0],1)), testFeatures), 1)\n",
    "print(trainFeatures)\n",
    "print(testFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Model\n",
    "\n",
    "\\begin{equation*}\n",
    "f_w(x) = \\frac {1}{1+e^{-\\sum_{i=0}^n{w_i x_i}}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LRmodel:\n",
    "    def __init__(self, weights):\n",
    "        self.w = weights\n",
    "        \n",
    "    def __init__(self, numFeatures):\n",
    "        self.w = np.ones(numFeatures)\n",
    "            \n",
    "    def predict(self, features):   \n",
    "\t\t# [TODO] Implement prediction based on the formulas above\n",
    "        return 0\n",
    "    \n",
    "    def getModelParams(self):\n",
    "        return self.w\n",
    "    \n",
    "    def setModelParams(self, w):\n",
    "        self.w = w\n",
    "\n",
    "\n",
    "model = LRmodel(trainFeatures.shape[1])\n",
    "\n",
    "print(\"Model weights: \", model.w)\n",
    "print(\"Expected values: [1. 1. 1. 1. 1. 1. 1.]\")\n",
    "\n",
    "print(\"Feature vector shape: \", trainFeatures.shape)\n",
    "print(\"Expected values: (623, 7)\")\n",
    "\n",
    "print(\"First 3 model evaluations: \", model.predict(trainFeatures)[0:3])\n",
    "print(\"Expected values: 0.96795449 0.84042498 0.96918524\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer\n",
    "\n",
    "### Loss function:\n",
    "\n",
    "\\begin{equation*}\n",
    "E(w) = \\frac {1} {N} \\sum_{i=1}^N{L(f_w(x_i),y_i)} \n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "E(w) = \\frac {1} {N} \\sum_{i=1}^N{[-y_i\\log(f_w(x_i)) - (1-y_i)\\log(1 -f_w(x_i))]} \n",
    "\\end{equation*}\n",
    "\n",
    "### Gradient descent:\n",
    "\n",
    "\\begin{equation*}\n",
    "w_0 = w_0 - \\mu \\frac{1}{N}\\sum_{i=1}^N {(f_w(x_i) - y_i)}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "w_j = w_j - \\mu \\frac{1}{N}\\sum_{i=1}^N {(f_w(x_i) - y_i) x_{ij}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def calculateLoss(self, features, labels):\n",
    "        # [TODO] Implement loss function based on the formulas above\n",
    "        return 0\n",
    "    \n",
    "    def calculateGradient(self, features, labels):\n",
    "        # [TODO] Implement gradient function based on the formulas above\n",
    "        return 0\n",
    "    \n",
    "    def updateModel(self, gradient, learningRate):\n",
    "        # [TODO] Implement model update based on the gradients\n",
    "    \n",
    "    def train(self, features, labels, learningRate, iters, lossValues):\n",
    "        for i in iters:\n",
    "\t\t\t# [TODO] Implement one itteration of training\n",
    "\n",
    "\t\t\t\n",
    "            loss = self.calculateLoss(features, labels)    \n",
    "            lossValues.append(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LRmodel(trainFeatures.shape[1])\n",
    "trainer = Trainer(model)\n",
    "\n",
    "print(\"Starting loss training: \", trainer.calculateLoss(trainFeatures, trainLabels))\n",
    "\n",
    "learningRate = 30\n",
    "lossValues = []\n",
    "iters = np.arange(1, 2000, 1)\n",
    "\n",
    "trainer.train(trainFeatures, trainLabels, learningRate, iters, lossValues)\n",
    "\n",
    "lossValues = np.array(lossValues)\n",
    "print(\"End loss training: \", lossValues[-1])\n",
    "\n",
    "plt.figure(1, figsize=(20, 8))\n",
    "plt.plot(iters, lossValues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def evaluate(self, features):\n",
    "        predictions = self.model.predict(features)\n",
    "        return predictions\n",
    "    \n",
    "    def calculateAPR(self, features, labels, threshold):\n",
    "        predictions = self.evaluate(features)\n",
    "        \n",
    "        numExamples = predictions.shape[0]\n",
    "        binaryPredictions = (predictions > threshold).astype(int)\n",
    "        \n",
    "        positivePredictions = np.where(binaryPredictions == 1)\n",
    "        negativePredictions = np.where(binaryPredictions == 0)\n",
    "        \n",
    "        # [TODO] Implement calculation of TP, FP, TN, FN, Precision, Recall and Accuracy\n",
    "        \n",
    "        # TP - Count of examples that were correctlly predicted as positive examples\n",
    "        \n",
    "        # FP - Count of examples that were incorectlly predicted as positive examples\n",
    "        \n",
    "        # FN - Count of examples that were incorectlly predicted as negative examples\n",
    "        \n",
    "        # TN - Count of examples that were correctlly predicted as negative examples\n",
    "        \n",
    "        \n",
    "        return Precision, Recall, Accuracy\n",
    "    \n",
    "    def plotAPR(self, resultsTest, resultsTrain, ranges):\n",
    "        plt.figure(1, figsize=(20, 15))\n",
    "        plt.subplot(211)\n",
    "        plt.plot(ranges, np.matrix(resultsTrain)[:,0], ranges, np.matrix(resultsTrain)[:,1], ranges, np.matrix(resultsTrain)[:,2])\n",
    "        plt.subplot(212)\n",
    "        plt.plot(ranges, np.matrix(resultsTest)[:,0], ranges, np.matrix(resultsTest)[:,1], ranges, np.matrix(resultsTest)[:,2])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluator = Evaluator(model)\n",
    "t = np.arange(0., 1., 0.001)\n",
    "resultsTest = []\n",
    "resultsTrain = []\n",
    "for i in t:\n",
    "    resultsTest.append(evaluator.calculateAPR(testFeatures, testLabels, i))\n",
    "    resultsTrain.append(evaluator.calculateAPR(trainFeatures, trainLabels, i))\n",
    "\n",
    "evaluator.plotAPR(resultsTest, resultsTrain, t)\n",
    "\n",
    "print(\"Model w: \", model.w)\n",
    "print(\"Accuracy: \", np.sum((model.predict(testFeatures)>0.5) == (testLabels==1))/testFeatures.shape[0])"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
