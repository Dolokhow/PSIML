{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network Workshop\n",
    "\n",
    "The aim of this workshop is to demonstrate the basics of using [TensorFlow](https://www.tensorflow.org/) for\n",
    "convolutional neural networks.\n",
    "\n",
    "TensorFlow is an open source system developed by Google Brain for working with computation graphs. It supports\n",
    "automatic differentiation, making it suitable for implementing backpropagation.\n",
    "\n",
    "Optimized implementation of convolutional network is not trivial, especially on GPU. Therefore, in your projects\n",
    "you are much more likely to use frameworks like TensorFlow than to code from scratch.\n",
    "\n",
    "This notebook will cover the basics, providing references to additional resources where needed. You are welcome\n",
    "to use many excellent tutorials on the web, including the [one from Google](https://www.tensorflow.org/get_started/get_started).\n",
    "\n",
    "Overview:\n",
    "* [Preparing data](#Preparing-data)\n",
    "* [Defining and examining a simple network](#Defining-and-examining-a-simple-network)\n",
    "* [Adding batch normalization](#Adding-batch-normalization)\n",
    "* [Training a more complex network](#Training-a-more-complex-network)\n",
    "* [Saving and loading models](#Saving-and-loading-models)\n",
    "* [Transfer learning](#Transfer-learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommended TensorFlow version is 1.9.0.** If you are working on a machine with GPU, it is recommended that you\n",
    "**install GPU version of TensorFlow** (`tensorflow-gpu` Python package). You will also need `matplotlib`.\n",
    "\n",
    "We begin by importing all modules that we will need, including TensorFlow. This also verifies that TensorFlow installation is OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from utils import load_cifar10, visualize_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data\n",
    "\n",
    "We will use CIFAR-10 dataset. Please download it from [here](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "(alternatively from [here](https://1drv.ms/u/s!ApgLrbSPQF9XirQ0fEqljE5_IT0q6g)\n",
    "or [here](https://1drv.ms/u/s!ApgLrbSPQF9XirQ16VxWmz_x0bRwMg)), and make sure to specify correct location\n",
    "in `cifar10_dir` below. We load the dataset by calling a utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_dir = 'cifar-10-batches-py'\n",
    "x_dev, y_dev, x_test, y_test = load_cifar10(cifar10_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is divided into part that can be used for training and validation (which we will call\n",
    "*development*), and test part.\n",
    "\n",
    "There are 50,000 dev images, and 10,000 test images. test images. All images are 32 x 32 pixels, and\n",
    "have 3 channels. Each image is assigned to one of 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dev data shape: ', x_dev.shape)\n",
    "print('Dev labels shape: ', y_dev.shape)\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('Class labels: ', np.unique(np.concatenate([y_dev, y_test])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define some useful constants to be used throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dev = x_dev.shape[0]\n",
    "num_test = x_test.shape[0]\n",
    "num_classes = len(np.unique(np.concatenate([y_dev, y_test])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/validation split\n",
    "\n",
    "From dev data we take 10% for validation, and use the rest for training.\n",
    "To make sure that train and dev set have the same distribution, we randomize\n",
    "dev set first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_val = num_dev // 10\n",
    "num_train = num_dev - num_val\n",
    "\n",
    "perm = np.random.permutation(num_dev)\n",
    "x_dev = x_dev[perm]\n",
    "y_dev = y_dev[perm]\n",
    "\n",
    "x_train = x_dev[:num_train]\n",
    "y_train = y_dev[:num_train]\n",
    "x_val = x_dev[num_train:]\n",
    "y_val = y_dev[num_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization\n",
    "\n",
    "We normalize all data by subtracting mean image from each sample.\n",
    "Note that the mean image is computed from training set only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_image = np.mean(x_train, axis=0)\n",
    "x_train -= mean_image\n",
    "x_val -= mean_image\n",
    "x_test -= mean_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing training examples\n",
    "\n",
    "Let's look at `sample_size` random examples from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10\n",
    "sample = x_train[[i for c in range(num_classes)\n",
    "                  for i in np.random.permutation(np.flatnonzero(y_train == c))[:sample_size]]]\n",
    "sample += mean_image\n",
    "plt.figure(figsize = (12, 12))\n",
    "plt.imshow(visualize_grid(sample))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what the classes represent, we can create an array of human-readable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining and examining a simple network\n",
    "\n",
    "We define a simple network consisting of basic layers:\n",
    "* convolutional layer,\n",
    "* max-pooling layer,\n",
    "* fully connected layer, and\n",
    "* ReLU activation function.\n",
    "\n",
    "TensorFlow supports many other layer types and activations. See https://www.tensorflow.org/api_guides/python/nn for official API documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line clears any network that might already exist in memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TensorBoard log file\n",
    "\n",
    "We will use TensorBoard to visualize various data about our network. TensorBoard parses log files (also called event files) generated by TensorFlow. We will be placing those files in a separate dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = './logs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new event file is created by instantiating a `tf.FileWriter` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(os.path.join(log_dir, 'simple_net'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for data\n",
    "First we define placeholders for input data (input image and its label) using `tf.placeholder`.\n",
    "We will eventually bind these to actual numerical data values.\n",
    "\n",
    "We choose to represent input data as 4D tensors whose shape is N x H x W x C, where:\n",
    "* N is the number of examples in a batch (batch size)\n",
    "* H is the height of each image in pixels\n",
    "* W is the height of each image in pixels\n",
    "* C is the number of channels (usually 3: R, G, B)\n",
    "\n",
    "This is the right way to represent the data for spatial operations like convolution. For fully connected layers, however, all dimensions except batch size will be collapsed into one.\n",
    "\n",
    "In `tf.placeholder`, if a dimension has value `None`, it will be set automatically once actual data is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_input():\n",
    "    x = tf.placeholder(tf.float32, [None, 32, 32, 3], name='x')\n",
    "    y = tf.placeholder(tf.int64, [None], name='y')\n",
    "    is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "    return x, y, is_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, is_training = setup_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional and pooling nodes\n",
    "Next we start defining the main \"body\" of the network.\n",
    "We start by adding a single convolutional layer with bias and ReLU activation.\n",
    "\n",
    "We use [tf.layers API](https://www.tensorflow.org/api_docs/python/tf/layers) to generate a whole layer by a single function call.\n",
    "It is also possible to create each parameter and operation node separately, and connect them together, but that quickly becomes\n",
    "cumbersome for bigger networks.\n",
    "\n",
    "TensorFlow also provides other high-level APIs, such as [TensorFlow-Slim](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim), which\n",
    "has become very popular, with a large number of [pretrained models](https://github.com/tensorflow/models/tree/master/research/slim) written in it.\n",
    "Fortunately, TF-Slim models can be quite easily combined with other TensorFlow APIs such as tf.layers.\n",
    "\n",
    "Convolutional layer is created by calling `tf.layers.conv2d`. Returned object is of type `tf.Tensor` and represents output activations of the layer.\n",
    "\n",
    "Bias is enabled by default, so it is not explicitly specified. `padding='SAME'` means that we allow padding of roughly half the kernel size\n",
    "(TensorFlow computes this value automatically), to avoid reduction in output size due to boundary effects. The other option is `padding='VALID'`, which means\n",
    "that padding is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(inputs=x, filters=32, kernel_size=[7, 7], strides=2, padding='SAME', activation=tf.nn.relu, name='conv1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we add a max-pooling node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2, padding='SAME', name='pool1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View default graph in TensorBoard\n",
    "\n",
    "We can write graph data to event file we create above. A graph can be passed to `FileWriter` constructor as well, in which case it is written to file immediately after the file is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should be able to run `tensorboard --logdir=./logs` from console (with your Python environment activated), and see the graph visualized in browser at `http://localhost:6006`.\n",
    "\n",
    "For more details please see official tutorial on [graph visualization](https://www.tensorflow.org/get_started/graph_viz).\n",
    "\n",
    "Note: graph visualization seems to work best in Google Chrome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining static information\n",
    "Most information about the network which is static (i.e. independent of input data)\n",
    "can be seen from TensorBoard graph visualization -- node names, connectivity, tensor sizes,\n",
    "some layer parameters, but not tensor values.\n",
    "\n",
    "This data is also acessible from Python code, which is useful in some situations.\n",
    "\n",
    "If we already have handles on nodes, for example because we just created them, such as `conv1`\n",
    "and `pool1` above, we can query their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conv1.shape)\n",
    "print(pool1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that shapes of activation tensors are computed automatically. Also, these tensors\n",
    "may have unknown dimensions which become known only when acutal input is presented.\n",
    "\n",
    "We may not have a handle on some nodes, for example internal parameters of `conv1` (kernel and bias).\n",
    "Those tensors are \"hidden\" inside the layer, because we used layers API. We can still access them\n",
    "using name lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_kernel = tf.get_default_graph().get_tensor_by_name('conv1/kernel:0')\n",
    "conv1_bias = tf.get_default_graph().get_tensor_by_name('conv1/bias:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names can be found from TensorBoard visualization, or by listing all operations (nodes) in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_default_graph().get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `conv1` prefix in both names (*name scope*) refers to the `name` parameter specified when creating\n",
    "the layer, and NOT the Python variable `conv1` that we assigned the result to. The `:0` suffix means that\n",
    "the tensor is the first (index 0) output of the node that produces it (`conv/kernel` and `conv1/bias`, respectively).\n",
    "\n",
    "We can get the shapes of kernel and bias as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conv1_kernel.shape)\n",
    "print(conv1_bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also access internal parameters of operations (rather than their tensor outputs) using\n",
    "`get_operation_by_name` followed by `get_attr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.get_default_graph().get_operation_by_name('conv1/Conv2D').get_attr('strides'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected layers\n",
    "Next we append a fully connected layer with 1024 output neurons and ReLU activation.\n",
    "In order to determine the shape of its parameter tensor, we need to know the number of input neurons, which depends on the shape of the `relu1` activation tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1_input_count = int(pool1.shape[1] * pool1.shape[2] * pool1.shape[3])\n",
    "fc1_output_count = 1024\n",
    "print([fc1_input_count, fc1_output_count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to append a fully connected layer, we need to flatten the spatial dimensions of `relu1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool1_flat = tf.reshape(pool1, [-1, fc1_input_count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to add a fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = tf.layers.dense(inputs=pool1_flat, units=fc1_output_count, activation=tf.nn.relu, name='fc1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add another fully connected layer with bias to output scores for 10 output classes. This layer has no nonlinearity following it, but it will be followed by a softmax function to convert scores to probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc2 = tf.layers.dense(inputs=fc1, units=num_classes, name='fc2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final classification\n",
    "We append a softmax layer to convert the scores coming from `fc2` into probabilities, as well as a \"top-k\" layer to get the three most probable guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = tf.nn.softmax(fc2)\n",
    "(guess_prob, guess_class) = tf.nn.top_k(prob, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing parameters and activations\n",
    "TensorBoard supports visualizing tensors as images using `tf.summary.image` function.\n",
    "This function adds a subnetwork that computes images for a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_image_summary(tensor, name):\n",
    "    with tf.variable_scope(name):\n",
    "        # Normalize to [0 1].\n",
    "        x_min = tf.reduce_min(tensor)\n",
    "        x_max = tf.reduce_max(tensor)\n",
    "        normalized = (tensor - x_min) / (x_max - x_min)\n",
    "\n",
    "        # Display random 3 slices.\n",
    "        return tf.summary.image('tensor', normalized, max_outputs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this we visualize some of the weights in `conv1_kernel`. Since each filter has 3\n",
    "input channels, it be visualized as an RGB image. Note that we need to transpose the\n",
    "tensor from (H, W, C, N) to (N, H, W, C) layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_kernel_summary = setup_image_summary(\n",
    "    tf.transpose(conv1_kernel, [3, 0, 1, 2]),\n",
    "    name='conv1_kernel_summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can visualize some of the activations in `conv1`. Use `setup_image_summary`\n",
    "in code below to visualize a subset of channels for example 0 in minibatch. Each channel\n",
    "should be visualized as a grayscale image. You can use [tf.slice](https://www.tensorflow.org/api_docs/python/tf/slice)\n",
    "to get example 0. If necessary, transpose into appropriate layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summaries can also be *merged*. We add a special `image_summaries` node that outputs the union of our two image summaries.\n",
    "Evaluating this node causes both summaries to be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_summaries = tf.summary.merge([conv1_kernel_summary, conv1_output_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update graph visualization\n",
    "We have added some new nodes, and we need to check if the new graph is OK.\n",
    "To update TensorBoard visualization, we just add a new graph to the event file.\n",
    "The visualizer will pick up the latest graph when its browser tab is refreshed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass\n",
    "Next we run one CIFAR-10 frame through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_random_image():\n",
    "    index = np.random.randint(0, num_train)\n",
    "    return index, x_train[[index]], y_train[[index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index, random_image, random_label = choose_random_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A TensorFlow graph is executed by creating a `tf.Session` object and calling its `run` method.\n",
    "A session object encapsulates the control and state of the TensorFlow runtime.\n",
    "The `run` method requires a list of output tensors that should be computed, and a mapping of input tensors to actual data that should be used. For more information, see the TensorFlow [Getting started](https://www.tensorflow.org/get_started/get_started) guide.\n",
    "\n",
    "Optionally we can also specify a device context such as `/cpu:0` or `/gpu:0`. For documentation on this see [this TensorFlow guide](https://www.tensorflow.org/tutorials/using_gpu). The default device is a GPU if available, and a CPU otherwise, so we can skip the device specification from now on.\n",
    "\n",
    "Note: if GPU is explicitly specified, but not available, a Python exception is thrown; current graph is invalidated, and needs to be cleared and rebuilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/cpu:0\") as dev: #\"/cpu:0\" or \"/gpu:0\"\n",
    "        # Initialize weights.\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Map inputs to data.\n",
    "        feed_dict = { x : random_image, y : random_label }\n",
    "\n",
    "        # Set up variables we want to compute.\n",
    "        variables = [guess_prob, guess_class, image_summaries]\n",
    "\n",
    "        # Perform forward pass.\n",
    "        guess_prob_value, guess_class_value, img_summ_value = sess.run(variables, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's see the image that was chosen, and networks predictions for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_classification(image, guess_class, guess_prob):\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    for i in range(3):\n",
    "        ind = guess_class[0, i]\n",
    "        prob = guess_prob[0, i]\n",
    "        print(\"Class: {0}\\tProbability: {1:0.0f}%\".format(class_names[ind], prob * 100))\n",
    "    print(\"Ground truth: {0}\".format(class_names[random_label[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_classification((random_image[0] + mean_image) / 255.0, guess_class_value, guess_prob_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write generated images to file. After running the next cell the images should be visible in TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_summary(img_summ_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and metric(s)\n",
    "\n",
    "We append more nodes to compute loss value, and the number of correctly predicted pixels.\n",
    "For loss we use `tf.sparse_softmax_cross_entropy_with_logits`. For other loss functions available\n",
    "out of the box in TensorFlow, see https://www.tensorflow.org/api_guides/python/nn#Losses and\n",
    "https://www.tensorflow.org/api_guides/python/nn#Classification.\n",
    "Of course, you can always build your own custom loss functions from simpler operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_metrics(y, y_out):\n",
    "    # Define loss function.\n",
    "    total_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=y_out)\n",
    "    mean_loss = tf.reduce_mean(total_loss)\n",
    "\n",
    "    # Add top three predictions.\n",
    "    prob = tf.nn.softmax(y_out)\n",
    "    (guess_prob, guess_class) = tf.nn.top_k(prob, k=3)\n",
    "\n",
    "    # Compute number of correct predictions.\n",
    "    is_correct = tf.equal(tf.argmax(y_out, 1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "    return mean_loss, accuracy, guess_prob, guess_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be reusing this function later for other architectures.\n",
    "Now we create metrics for our current network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_loss, accuracy, guess_prob, guess_class = setup_metrics(y, fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing loss and metric(s)\n",
    "We would like to use TensorBoard to visualize loss value and correct count.\n",
    "We add special nodes that generate those logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_scalar_summaries():\n",
    "    mean_loss_summary = tf.summary.scalar('mean_loss', mean_loss)\n",
    "    accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
    "    return tf.summary.merge([mean_loss_summary, accuracy_summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_summaries = setup_scalar_summaries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "Finally, we define the optimization algorithm to be used for training. We use the Adam optimizer with learning rate 5e-4. For other choices see https://www.tensorflow.org/api_guides/python/train#Optimizers.\n",
    "\n",
    "Optimizer's `minimize` method essentially generates a network that performs backward pass based on the forward pass network that we defined, and passed to the optimizer via argument to `minimize`.\n",
    "The result of this method is a dummy node `train_step` which, when evaluated triggers execution of backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_optimizer(loss, learning_rate):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    # Batch normalization in TensorFlow requires this extra dependency\n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(extra_update_ops):\n",
    "        train_step = optimizer.minimize(loss)\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be reusing this function for other architectures. Now we create optimizer for our current network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = setup_optimizer(mean_loss, 5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding an optional backward pass\n",
    "Above we saw how to execute forward pass using `tf.Session.run`. Now we wrap that into a function\n",
    "(since we will be calling it in a loop to train the network). We also add an option to execute a\n",
    "backward pass by passing the extra argument `training`. That way we can use the same function for\n",
    "both training (forward + backward), and evaluation (forward only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iteration(session, variables, x_data, y_data, training=None):\n",
    "    if training != None:\n",
    "        variables += [training]\n",
    "\n",
    "    # Map inputs to data.\n",
    "    feed_dict = {x : x_data, y : y_data, is_training : training != None}\n",
    "\n",
    "    # Compute variable values, and perform training step if required.\n",
    "    values = session.run(variables, feed_dict=feed_dict)\n",
    "\n",
    "    # Return loss value and number of correct predictions.\n",
    "    return values[:-1] if training != None else values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main training/evaluation loop\n",
    "The following is a simple function which trains or evaluates current model for a given number\n",
    "of epochs by repeatedly calling the `run_iteration` function defined above. It also takes care of:\n",
    "* aggregating loss and accuracy values over all minibatches\n",
    "* plotting loss and accuracy values over time.\n",
    "\n",
    "The code below assumes that `mean_loss`, `accuracy`, and `scalar_summaries` are defined externally.\n",
    "Optionally, the caller may also define `image_summaries`, if they want some image summaries (like kernel\n",
    "and activation visualizations in the form of images) to be also included.\n",
    "All those definitions will change depending on the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(session, x, y, epochs, batch_size, print_every, training):\n",
    "\n",
    "    # Number of examples in dataset.\n",
    "    dataset_size = x.shape[0]\n",
    "\n",
    "    # Count iterations since the beginning of training.\n",
    "    iter_cnt = 0\n",
    "\n",
    "    for e in range(epochs):\n",
    "        # Randomize training examples for each epoch.\n",
    "        train_indices = np.random.permutation(dataset_size)\n",
    "\n",
    "        # Keep track of performance stats (loss and accuracy) in current epoch.\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        # Iterate over the dataset once.\n",
    "        for start_idx in range(0, dataset_size, batch_size):\n",
    "\n",
    "            # Indices for current batch.\n",
    "            idx = train_indices[start_idx : min(start_idx + batch_size, dataset_size)]\n",
    "\n",
    "            # Get batch size (may not be equal to batch_size near the end of dataset).\n",
    "            actual_batch_size = y[idx].shape[0]\n",
    "\n",
    "            # Set up variables that we want to compute.\n",
    "            variables = [mean_loss, accuracy, scalar_summaries]\n",
    "            has_image_summaries = image_summaries != None\n",
    "            if has_image_summaries:\n",
    "                variables += [image_summaries,]\n",
    "\n",
    "            # Compute loss, accuracy, and scalar summaries, and optionally perform backward pass.\n",
    "            results = run_iteration(session, variables, x[idx], y[idx], training)\n",
    "\n",
    "            # Unpack results.\n",
    "            loss, acc, scl_summ = results[:3]\n",
    "            if has_image_summaries:\n",
    "                img_summ = results[3]\n",
    "\n",
    "            # Update performance stats.\n",
    "            total_loss += loss * actual_batch_size\n",
    "            total_correct += acc * actual_batch_size\n",
    "\n",
    "            # Add scalar summaries to event file.\n",
    "            if (training is not None):\n",
    "                writer.add_summary(scl_summ, iter_cnt)\n",
    "\n",
    "            # Print status, and add image summaries (if any).\n",
    "            if (training is not None) and (iter_cnt % print_every) == 0:\n",
    "                print(\"Iteration {0}: with minibatch training loss = {1:.3g} and accuracy of {2:.2f}%\".format(iter_cnt, loss, acc * 100))\n",
    "                if has_image_summaries:\n",
    "                    writer.add_summary(img_summ, iter_cnt)\n",
    "\n",
    "            iter_cnt += 1\n",
    "\n",
    "        # Compute performance stats for current epoch.\n",
    "        avg_accuracy = total_correct / dataset_size\n",
    "        avg_loss = total_loss / dataset_size\n",
    "\n",
    "        print(\"Epoch {2}, Overall loss = {0:.3g} and accuracy of {1:.2f}%\".format(avg_loss, avg_accuracy * 100, e + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model for one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('Training')\n",
    "run_model(sess, x=x_train, y=y_train, epochs=1, batch_size=64, print_every=100, training=train_step)\n",
    "print('Validation')\n",
    "run_model(sess, x=x_val, y=y_val, epochs=1, batch_size=64, print_every=100, training=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View summaries in TensorBoard log\n",
    "Now you should be able to refresh your TensorBoard tab and see the summaries.\n",
    "For more details please see [official tutorial](https://www.tensorflow.org/get_started/summaries_and_tensorboard) on summaries.\n",
    "TensorFlow also supports other kinds of summaries, such as [histograms](https://www.tensorflow.org/get_started/tensorboard_histograms). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some predictions\n",
    "Accuracy should be somewhat better now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index, random_image, random_label = choose_random_image()\n",
    "guess_class_value, guess_prob_value = run_iteration(sess, [guess_class, guess_prob], random_image, random_label)\n",
    "visualize_classification((random_image[0] + mean_image) / 255.0, guess_class_value, guess_prob_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding batch normalization\n",
    "\n",
    "Now we will modify the simple architecture by adding batch normalization. We expect this network to train faster, and achieve better\n",
    "accuracy for the same number of weight updates.\n",
    "\n",
    "Your task is to implement `bn_net` function below so that it creates the same network as in the previous section (with convolution, pooling,\n",
    "and two fully connected layers), except that there should also be a batch normalization layer after the convolution layer.\n",
    "\n",
    "Arguments of `bn_net` are placeholders for data (`x`), labels (`y`), and boolean flag (`is_training`) for indicating if the network should\n",
    "perform training or validation version of the computation on the input data. While `is_training` was completely ignored in the previous\n",
    "network, *here it should actually matter* (why?). `bn_net` should return the output (prediction) tensor of the network.\n",
    "\n",
    "API reference for batch normalization is at https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_net(x, y, is_training):\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input, metrics and optimizer are the same as before, so we can assemble the whole network.\n",
    "If you implemented `bn_net` correctly, this code should run without modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "writer = tf.summary.FileWriter(os.path.join(log_dir, 'bn_net'))\n",
    "x, y, is_training = setup_input()\n",
    "y_out = bn_net(x, y, is_training)\n",
    "mean_loss, accuracy, guess_prob, guess_class = setup_metrics(y, y_out)\n",
    "scalar_summaries = setup_scalar_summaries()\n",
    "image_summaries = None\n",
    "train_step = setup_optimizer(mean_loss, 5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to train and validate the network with batch normalization as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    run_model(sess, x=x_train, y=y_train, epochs=1, batch_size=64, print_every=100, training=train_step)\n",
    "    print('Validation')\n",
    "    run_model(sess, x=x_val, y=y_val, epochs=1, batch_size=64, print_every=100, training=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a more complex network\n",
    "\n",
    "Please download TensorBoard event file from [here](https://1drv.ms/u/s!ApgLrbSPQF9XirQrPV7L1GOhxkc-ig).\n",
    "Your task is to build the architecture contained in the event file `cifar10_net_log\\events.out.tfevents.1500743084.localhost`, and\n",
    "train it on CIFAR-10. You should train for 8 epochs with batch size 100 and learning rate 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar10_net(x, y, is_training):\n",
    "    # TODO\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "writer = tf.summary.FileWriter(os.path.join(log_dir, 'complex_net'))\n",
    "x, y, is_training = setup_input()\n",
    "y_out = cifar10_net(x, y, is_training)\n",
    "mean_loss, accuracy, guess_prob, guess_class = setup_metrics(y, y_out)\n",
    "scalar_summaries = setup_scalar_summaries()\n",
    "image_summaries = None\n",
    "train_step = setup_optimizer(mean_loss, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training')\n",
    "    run_model(sess, x=x_train, y=y_train, epochs=8, batch_size=100, print_every=100, training=train_step)\n",
    "    print('Validation')\n",
    "    run_model(sess, x=x_val, y=y_val, epochs=1, batch_size=100, print_every=100, training=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading models\n",
    "\n",
    "Saving is done using `tf.train.Saver` class:\n",
    "* `save` method saves both network definition and weights.\n",
    "* `export_meta_graph` method saves only network definition.\n",
    "\n",
    "Loading is done in two stages:\n",
    "* `tf.train.import_meta_graph` function loads network definition, and returns a saver object that was used to save the model.\n",
    "* `restore` method of the returned saver object loads the weights.\n",
    "\n",
    "Note that since weights are available only inside a session, `save` and `restore` methods above require a session object as a parameter.\n",
    "\n",
    "Official TensorFlow documentation: [Saving and Restoring Variables](https://www.tensorflow.org/api_guides/python/state_ops#Saving_and_Restoring_Variables), [tf.train.Saver class](https://www.tensorflow.org/api_docs/python/tf/train/Saver), [tf.train.import_meta_graph function](https://www.tensorflow.org/api_docs/python/tf/train/import_meta_graph).\n",
    "\n",
    "Useful unofficial tutorial on saving and loading: http://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/\n",
    "\n",
    "Many pretrained models found online do not contain network definition (meta-graph) files. The authors instead provide TensorFlow\n",
    "code to create the network graph. For such graphs, weights can also be restored from checkpoint file. Network definition file is\n",
    "just a way to avoid copying the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "\n",
    "In this section we will take a model which is pretrained on ImageNet for 1000-class image classification task, and\n",
    "finetune it for our 10-class CIFAR-10 classification task.\n",
    "\n",
    "Pretrained model is given by meta-graph file (containing network definition), and checkpoint file (containing weights).\n",
    "Please download pretrained model from [here](https://1drv.ms/u/s!ApgLrbSPQF9XirQpuN32y0577zey8g)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_meta_graph = os.path.join('mobilenet_v2_1.0_224', 'mobilenet_v2_1.0_224.meta')\n",
    "pretrained_checkpoint = os.path.join('mobilenet_v2_1.0_224', 'mobilenet_v2_1.0_224.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the CIFAR-10 task we need to perform the following two modifications to the pretrained model at the very minimum:\n",
    "* Process CIFAR-10 images so that their size becomes what pretrained model expects\n",
    "* Adapt the layers which perform final classification so that the number of output neurons is 10 (the number of\n",
    "classes in the CIFAR-10 classification task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get names of relevant nodes\n",
    "\n",
    "Modifying input part of a pretrained network is somewhat cumbersome. It must be done simultaneously with loading network\n",
    "definition, by passing to `tf.train.import_meta_graph` a mappping from input tensors of the pretrained network to new input tensors.\n",
    "\n",
    "First we load pretrained network definition only to get the names of input placeholder nodes that we want to replace.\n",
    "This step can be skipped if these names are already known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "_ = tf.train.import_meta_graph(pretrained_meta_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to get the nodes' names is using TensorBoard. It can also be done programmatically, as explained above\n",
    "(for example, using `tf.get_default_graph().get_operations()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(os.path.join(log_dir, 'transfer_net'))\n",
    "writer.add_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After inspecting TensorFlow graph visualization, we find that\n",
    "* the input nodes are `image` and `is_training`\n",
    "* final classification is performed in the node group (subgraph) `MobilenetV2/Logits/Conv2d_1c_1x1` which implements 1x1 convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify input and output\n",
    "\n",
    "Next we clear the default graph, and start creating new one, with modified input subnetwork which upsamples input image\n",
    "to match the size expected by pretrained network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "writer = tf.summary.FileWriter(os.path.join(log_dir, 'transfer_net'))\n",
    "x, y, is_training = setup_input()\n",
    "x_upsampled = tf.image.resize_images(x, [224, 224])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we reload pretrained network definition, replacing pretrained input placeholders with new tensors we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.import_meta_graph(pretrained_meta_graph, input_map={'image:0' : x_upsampled, 'is_training:0' : is_training})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to replace the node group `MobilenetV2/Logits/Conv2d_1c_1x1` by a 1x1 convolution with different number of output\n",
    "channels. To that end, we get a handle to the tensor immediately preceding `MobilenetV2/Logits/Conv2d_1c_1x1` in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = tf.get_default_graph().get_tensor_by_name('MobilenetV2/Logits/Dropout/cond/Merge:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach a new prediction layer for modified task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('MobilenetV2/Logits'):\n",
    "      conv_1x1 = tf.layers.conv2d(inputs=feat, filters=num_classes, kernel_size=[1, 1], strides=1, name='conv2d_1x1_modified')\n",
    "      output = tf.squeeze(conv_1x1, [1, 2], name='output_modified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete network definition\n",
    "Add metrics and optimizer as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_loss, accuracy, guess_prob, guess_class = setup_metrics(y, output)\n",
    "scalar_summaries = setup_scalar_summaries()\n",
    "image_summaries = None\n",
    "train_step = setup_optimizer(mean_loss, 5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again write out the graph to make sure surgery succeeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and validate network (at your own risk!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only now we can restore weights from checkpoint, because weights exist only inside a session.\n",
    "\n",
    "Then we train the network as before. Note that this training is *extremely slow on CPU*, due to bigger network.\n",
    "Also observe that we still need to initialize variables, because we have introduced new ones, i.e. not all\n",
    "variables that exist in the network are restored from checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, pretrained_checkpoint)\n",
    "    print('Training')\n",
    "    run_model(sess, x_train, y_train, epochs=1, batch_size=64, print_every=100, training=train_step)\n",
    "    print('Validation')\n",
    "    run_model(sess, x_val, y_val, epochs=1, batch_size=64, print_every=100, training=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
